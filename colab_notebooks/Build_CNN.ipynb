{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jgbeni/BirdPics.git\n",
        "!mv BirdPics/utils .\n",
        "!rm -r BirdPics\n",
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5oajkLblM_T",
        "outputId": "6ce22e85-698d-4e0c-e08d-e4b78fc10b98"
      },
      "id": "H5oajkLblM_T",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BirdPics'...\n",
            "remote: Enumerating objects: 62, done.\u001b[K\n",
            "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 62 (delta 20), reused 38 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (62/62), 6.79 MiB | 13.43 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n",
            "mv: cannot move 'BirdPics/utils' to './utils': Directory not empty\n",
            "total 12\n",
            "drwx------ 5 root root 4096 Nov  6 11:28 drive\n",
            "drwxr-xr-x 1 root root 4096 Nov  4 14:36 sample_data\n",
            "drwxr-xr-x 3 root root 4096 Nov  6 11:27 utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "04580ba5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04580ba5",
        "outputId": "1d94ec45-5b2d-41d9-ad46-57a42bff0706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import utils.data_preprocessing as dp\n",
        "import numpy as np\n",
        "import h5py\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir = '/content/drive/MyDrive/BirdPics'\n",
        "os.makedirs(dir+'/models',exist_ok=True)"
      ],
      "metadata": {
        "id": "JPe0jNTcliwL"
      },
      "id": "JPe0jNTcliwL",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "38a7101f",
      "metadata": {
        "id": "38a7101f"
      },
      "outputs": [],
      "source": [
        "f = h5py.File(dir+'/data/bird_data.hdf5', \"r\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,Y_train = f['train']['X'],np.copy(f['train']['Y'])\n",
        "X_val,Y_val = f['val']['X'],np.copy(f['val']['Y'])"
      ],
      "metadata": {
        "id": "_5K1ZQbjoTqD"
      },
      "id": "_5K1ZQbjoTqD",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "dd03c10b",
      "metadata": {
        "id": "dd03c10b"
      },
      "outputs": [],
      "source": [
        "Y_train = dp.prepare_labels(Y_train)\n",
        "Y_val = dp.prepare_labels(Y_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dp.HDF5Dataset(X_train,Y_train,train=True)\n",
        "val_dataset = dp.HDF5Dataset(X_val,Y_val)"
      ],
      "metadata": {
        "id": "VIfZN8Tpodmz"
      },
      "id": "VIfZN8Tpodmz",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, num_workers=8, batch_size=batch_size, pin_memory=True,\n",
        "                                                shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, num_workers=8, batch_size=batch_size, pin_memory=True,\n",
        "                                                shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBfvpfufo-lu",
        "outputId": "c0110a3c-1493-4780-efd8-a3b7a21bb6ae"
      },
      "id": "wBfvpfufo-lu",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the model"
      ],
      "metadata": {
        "id": "BfoyRVnDHxPh"
      },
      "id": "BfoyRVnDHxPh"
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Net(nn.Module):\n",
        "   def __init__(self, in_channels, num_classes):\n",
        "\n",
        "       \"\"\"\n",
        "       Building blocks of convolutional neural network.\n",
        "\n",
        "       Parameters:\n",
        "           * in_channels: Number of channels in the input image (for grayscale images, 1)\n",
        "           * num_classes: Number of classes to predict. In our problem, 10 (i.e digits from  0 to 9).\n",
        "       \"\"\"\n",
        "       super(CNN_Net, self).__init__()\n",
        "\n",
        "       # 1st convolutional layer\n",
        "       self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3)\n",
        "       # Max pooling layer\n",
        "       self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "       # 2nd convolutional layer\n",
        "       self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
        "       # 3rd convolutional layer\n",
        "       self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "       # 4rd convolutional layer\n",
        "       self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "       #Dropout\n",
        "       self.dropout = nn.Dropout(0.2)\n",
        "       # Fully connected layers\n",
        "       self.fc1 = nn.Linear(128*12*12, 500)\n",
        "       self.fc2 = nn.Linear(500,num_classes)\n",
        "\n",
        "   def forward(self, x):\n",
        "       \"\"\"\n",
        "       Define the forward pass of the neural network.\n",
        "\n",
        "       Parameters:\n",
        "           x: Input tensor.\n",
        "\n",
        "       Returns:\n",
        "           torch.Tensor\n",
        "               The output tensor after passing through the network.\n",
        "       \"\"\"\n",
        "       x = F.relu(self.conv1(x))  # Apply first convolution and ReLU activation\n",
        "       x = self.pool(x)           # Apply max pooling\n",
        "       x = F.relu(self.conv2(x))  # Apply second convolution and ReLU activation\n",
        "       x = self.pool(x)           # Apply max pooling\n",
        "       x = F.relu(self.conv3(x))  # Apply third convolution and ReLU activation\n",
        "       x = self.pool(x)           # Apply max pooling\n",
        "       x = F.relu(self.conv4(x))  # Apply third convolution and ReLU activation\n",
        "       x = self.pool(x)           # Apply max pooling\n",
        "       x = x.reshape(x.shape[0], -1)  # Flatten the tensor\n",
        "       x = self.dropout(x) # Dropout\n",
        "       x = F.relu(self.fc1(x))            # Apply fully connected layer 1\n",
        "       x = self.fc2(x) # Fully connected layer 2\n",
        "       return x\n",
        "model = CNN_Net(in_channels=3, num_classes=3).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "KA1bEZu1H0e_",
        "outputId": "1d8f888d-c76c-4c79-c3f9-dd0d99a7ab8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KA1bEZu1H0e_",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_Net(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc1): Linear(in_features=18432, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Ou53fmfZJz6C"
      },
      "id": "Ou53fmfZJz6C"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "pOkJhcL2vFHS"
      },
      "outputs": [],
      "source": [
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001 ,weight_decay=1e-5)"
      ],
      "id": "pOkJhcL2vFHS"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CbBgZijYwH2E",
        "outputId": "f01dec4f-4379-43af-a8d2-72a0d2b64bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/312 [00:00<?, ?it/s]Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a83489109a0><function _MultiProcessingDataLoaderIter.__del__ at 0x7a83489109a0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "        Exception ignored in: self._shutdown_workers()self._shutdown_workers()\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7a83489109a0>\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "Exception ignored in: Traceback (most recent call last):\n",
            "    <function _MultiProcessingDataLoaderIter.__del__ at 0x7a83489109a0>      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "if w.is_alive():if w.is_alive():    \n",
            "\n",
            " \n",
            "self._shutdown_workers()Traceback (most recent call last):\n",
            " \n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "            self._shutdown_workers() if w.is_alive():\n",
            "   \n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            " ^  ^     ^^  ^^if w.is_alive(): ^^\n",
            " ^^  ^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^^Exception ignored in: ^\n",
            "\n",
            "^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7a83489109a0>  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    ^    ^\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^assert self._parent_pid == os.getpid(), 'can only test a child process'^Traceback (most recent call last):\n",
            "\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "^   ^^      ^ self._shutdown_workers()  \n",
            " ^ \n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "          assert self._parent_pid == os.getpid(), 'can only test a child process'^  if w.is_alive(): \n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            " \n",
            "            assert self._parent_pid == os.getpid(), 'can only test a child process'^^ \n",
            " ^^ ^^  ^^    ^^  Exception ignored in:  ^^^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7a83489109a0> Exception ignored in: ^^ \n",
            " ^ ^^^ Traceback (most recent call last):\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7a83489109a0>^  ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "\n",
            "^ ^^^^Traceback (most recent call last):\n",
            "     ^^self._shutdown_workers()^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "^^^     ^\n",
            "^^^ self._shutdown_workers()^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "^^ ^^^^^    \n",
            "^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "^^^^if w.is_alive():^^^^    ^\n",
            "^^^ ^if w.is_alive():^^^ ^^^\n",
            "\n",
            " ^^^^ ^   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^ ^^ ^    ^ ^^ ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^ ^^^ \n",
            "^^ ^^^ ^^^ ^ ^^^ ^^^ ^^\n",
            "^^ ^ ^^^AssertionError^^: ^^^ ^^^^^ ^ ^\n",
            "\n",
            "^can only test a child process^^^ ^^^ ^AssertionError^^: ^^^^ can only test a child process^^^^^\n",
            "^^^^\n",
            "^^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^^^^    ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "^^^\n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^ ^    ^\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process' ^^AssertionError^ ^ \n",
            "^:   ^ can only test a child process ^ ^\n",
            "^ \n",
            "^ ^AssertionError  ^ :  can only test a child process ^ \n",
            "^    ^^^Exception ignored in:  ^^^^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7a83489109a0>^^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "^^^    ^self._shutdown_workers()^^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "^^^^    ^^^if w.is_alive():^^\n",
            "^^^ ^^^^ ^^ ^\n",
            "^ AssertionError^ ^:  ^^can only test a child process ^^^\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError: \n",
            "can only test a child process^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "\n",
            "    AssertionError: assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n",
            "\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "100%|██████████| 312/312 [02:19<00:00,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss 2.394 - train acc. 34.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val loss 1.099 - val acc. 33.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 50/312 [00:26<02:18,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1307000046.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtrain_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mtrain_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrain_correct\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtrain_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "n_total_steps = len(train_loader)\n",
        "num_epochs = 30\n",
        "\n",
        "max_val = 62.\n",
        "PATH = os.path.join(dir,'models/cnn_v1.pth')\n",
        "\n",
        "train_loss,val_loss = np.zeros(num_epochs,dtype=np.float32),np.zeros(num_epochs,dtype=np.float32)\n",
        "train_acc,val_acc = np.zeros(num_epochs,dtype=np.float32),np.zeros(num_epochs,dtype=np.float32)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_correct,train_samples = 0,0\n",
        "    val_correct,val_samples = 0,0\n",
        "    for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
        "        # origin shape: [32, 3, 224, 224] = 32, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_loss[epoch] += loss.item()/len(train_loader)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_samples += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_acc[epoch] = 100.0 * train_correct / train_samples\n",
        "    print('train loss %.3f - train acc. %.2f' %(train_loss[epoch],train_acc[epoch]))\n",
        "\n",
        "\n",
        "    for val_images, val_labels in val_loader:\n",
        "        val_images = val_images.to(device)\n",
        "        val_labels = val_labels.type(torch.LongTensor)\n",
        "        val_labels = val_labels.to(device)\n",
        "        outputs = model(val_images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        val_samples += val_labels.size(0)\n",
        "        val_correct += (predicted == val_labels).sum().item()\n",
        "\n",
        "        val_loss[epoch] += criterion(outputs, val_labels).item()/len(val_loader)\n",
        "    val_acc[epoch] = 100.0 * val_correct / val_samples\n",
        "    if val_acc[epoch] > max_val:\n",
        "        max_val = val_acc[epoch]\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "    print('val loss %.3f - val acc. %.2f' %(val_loss[epoch],val_acc[epoch]))\n",
        "\n",
        "print('Finished Training')"
      ],
      "id": "CbBgZijYwH2E"
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez(os.path.join(dir,'models/cnn_v1.npz'),train_loss=train_loss,val_loss=val_loss,train_acc=train_acc,val_acc=val_acc)"
      ],
      "metadata": {
        "id": "kLUEtPC9DN3d"
      },
      "id": "kLUEtPC9DN3d",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}