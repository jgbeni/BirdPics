{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jgbeni/BirdPics.git\n",
        "!mv BirdPics/utils .\n",
        "!rm -r BirdPics\n",
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5oajkLblM_T",
        "outputId": "8ea7d2d3-6e76-462a-fe70-4c8d38612971"
      },
      "id": "H5oajkLblM_T",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BirdPics'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 48 (delta 14), reused 31 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (48/48), 6.75 MiB | 25.79 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n",
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Nov  4 14:36 sample_data\n",
            "drwxr-xr-x 2 root root 4096 Nov  5 22:22 utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "04580ba5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04580ba5",
        "outputId": "21684b68-667e-4d18-dde3-05b71bb96f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import utils.data_preprocessing as dp\n",
        "import numpy as np\n",
        "import h5py\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir = '/content/drive/MyDrive/BirdPics'\n",
        "os.makedirs(dir+'/models',exist_ok=True)"
      ],
      "metadata": {
        "id": "JPe0jNTcliwL"
      },
      "id": "JPe0jNTcliwL",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "38a7101f",
      "metadata": {
        "id": "38a7101f"
      },
      "outputs": [],
      "source": [
        "f = h5py.File(dir+'/data/bird_data.hdf5', \"r\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,Y_train = f['train']['X'],np.copy(f['train']['Y'])\n",
        "X_val,Y_val = f['val']['X'],np.copy(f['val']['Y'])"
      ],
      "metadata": {
        "id": "_5K1ZQbjoTqD"
      },
      "id": "_5K1ZQbjoTqD",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dd03c10b",
      "metadata": {
        "id": "dd03c10b"
      },
      "outputs": [],
      "source": [
        "Y_train = dp.prepare_labels(Y_train)\n",
        "Y_val = dp.prepare_labels(Y_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dp.HDF5Dataset(X_train,Y_train,train=True)\n",
        "val_dataset = dp.HDF5Dataset(X_val,Y_val)"
      ],
      "metadata": {
        "id": "VIfZN8Tpodmz"
      },
      "id": "VIfZN8Tpodmz",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, num_workers=8, batch_size=batch_size, pin_memory=True,\n",
        "                                                shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, num_workers=8, batch_size=batch_size, pin_memory=True,\n",
        "                                                shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBfvpfufo-lu",
        "outputId": "8e455015-3109-4c5f-807e-4aa86d6eaf99"
      },
      "id": "wBfvpfufo-lu",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the model"
      ],
      "metadata": {
        "id": "BfoyRVnDHxPh"
      },
      "id": "BfoyRVnDHxPh"
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "images,labels = next(dataiter)\n",
        "print(images.shape)\n",
        "print(labels.dtype)"
      ],
      "metadata": {
        "id": "2nzdUY7ZIKW_",
        "outputId": "6966f1ca-7632-4ba5-bd9f-97045133ff47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2nzdUY7ZIKW_",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 224, 224])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv1 = nn.Conv2d(3,16,3)\n",
        "pool = nn.MaxPool2d(2,2)\n",
        "conv2 = nn.Conv2d(16,32,3)\n",
        "conv3 = nn.Conv2d(32,64,3)\n",
        "conv4 = nn.Conv2d(64,64,3)\n",
        "\n",
        "x = conv1(images)\n",
        "#print(x.shape)\n",
        "x = pool(x)\n",
        "#print(x.shape)\n",
        "x = conv2(x)\n",
        "#print(x.shape)\n",
        "x = pool(x)\n",
        "#print(x.shape)\n",
        "x = conv3(x)\n",
        "#print(x.shape)\n",
        "x = pool(x)\n",
        "x = conv4(x)\n",
        "#print(x.shape)\n",
        "x = pool(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "1eYFiiutIRo5",
        "outputId": "992aadcd-eba7-411b-eeaf-a8b5996c4edb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1eYFiiutIRo5",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 64, 12, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Net(nn.Module):\n",
        "   def __init__(self, in_channels, num_classes):\n",
        "\n",
        "       \"\"\"\n",
        "       Building blocks of convolutional neural network.\n",
        "\n",
        "       Parameters:\n",
        "           * in_channels: Number of channels in the input image (for grayscale images, 1)\n",
        "           * num_classes: Number of classes to predict. In our problem, 10 (i.e digits from  0 to 9).\n",
        "       \"\"\"\n",
        "       super(CNN_Net, self).__init__()\n",
        "\n",
        "       # 1st convolutional layer\n",
        "       self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3)\n",
        "       # Max pooling layer\n",
        "       self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "       # 2nd convolutional layer\n",
        "       self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
        "       # 3rd convolutional layer\n",
        "       self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "       # 4rd convolutional layer\n",
        "       self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "       #Dropout\n",
        "       self.dropout50 = nn.Dropout(0.5)\n",
        "       # Fully connected layers\n",
        "       self.fc1 = nn.Linear(64*12*12, 500)\n",
        "       self.fc2 = nn.Linear(500,num_classes)\n",
        "\n",
        "   def forward(self, x):\n",
        "       \"\"\"\n",
        "       Define the forward pass of the neural network.\n",
        "\n",
        "       Parameters:\n",
        "           x: Input tensor.\n",
        "\n",
        "       Returns:\n",
        "           torch.Tensor\n",
        "               The output tensor after passing through the network.\n",
        "       \"\"\"\n",
        "       x = F.relu(self.conv1(x))  # Apply first convolution and ReLU activation\n",
        "       x = self.pool(x)           # Apply max pooling\n",
        "       x = F.relu(self.conv2(x))  # Apply second convolution and ReLU activation\n",
        "       x = self.pool(x)           # Apply max pooling\n",
        "       x = F.relu(self.conv3(x))  # Apply third convolution and ReLU activation\n",
        "       x = self.pool(x)           # Apply max pooling\n",
        "       x = x.reshape(x.shape[0], -1)  # Flatten the tensor\n",
        "       x = self.dropout50(x) #Apply 50% Dropout\n",
        "       x = F.relu(self.fc1(x))            # Apply fully connected layer 1\n",
        "       x = self.dropout50(x) #Apply 50% Dropout\n",
        "       x = self.fc2(x) # Fully connected layer 2\n",
        "       return x\n",
        "model = CNN_Net(in_channels=3, num_classes=3).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "KA1bEZu1H0e_",
        "outputId": "40e6e9aa-88b4-403b-f565-b14743ffea58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KA1bEZu1H0e_",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_Net(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (dropout50): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=9216, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Ou53fmfZJz6C"
      },
      "id": "Ou53fmfZJz6C"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pOkJhcL2vFHS"
      },
      "outputs": [],
      "source": [
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001 ,weight_decay=1e-5)"
      ],
      "id": "pOkJhcL2vFHS"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "CbBgZijYwH2E",
        "outputId": "db56d646-6626-4ad0-e3f6-84462ed2ed73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/623 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "  0%|          | 0/623 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/content/utils/data_preprocessing.py\", line 22, in __getitem__\n    image_np = np.array(self.imgs[idx].transpose(2,0,1),float)\n                        ~~~~~~~~~^^^^^\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"/usr/local/lib/python3.12/dist-packages/h5py/_hl/dataset.py\", line 840, in __getitem__\n    return self._fast_reader.read(args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"h5py/_selector.pyx\", line 375, in h5py._selector.Reader.read\nOSError: [Errno 107] Can't synchronously read data (file read failed: time = Wed Nov  5 22:44:26 2025\n, filename = '/content/drive/MyDrive/BirdPics/data/bird_data.hdf5', file descriptor = 47, errno = 107, error message = 'Transport endpoint is not connected', buf = 0x30ac5620, total read size = 3656, bytes this sub-read = 3656, offset = 5688)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1196114016.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtrain_correct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mval_correct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m# origin shape: [32, 3, 224, 224] = 32, 3, 1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# input_layer: 3 input channels, 6 output channels, 5 kernel size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data, worker_idx)\u001b[0m\n\u001b[1;32m   1549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# be constructed, don't try to instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/content/utils/data_preprocessing.py\", line 22, in __getitem__\n    image_np = np.array(self.imgs[idx].transpose(2,0,1),float)\n                        ~~~~~~~~~^^^^^\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"/usr/local/lib/python3.12/dist-packages/h5py/_hl/dataset.py\", line 840, in __getitem__\n    return self._fast_reader.read(args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"h5py/_selector.pyx\", line 375, in h5py._selector.Reader.read\nOSError: [Errno 107] Can't synchronously read data (file read failed: time = Wed Nov  5 22:44:26 2025\n, filename = '/content/drive/MyDrive/BirdPics/data/bird_data.hdf5', file descriptor = 47, errno = 107, error message = 'Transport endpoint is not connected', buf = 0x30ac5620, total read size = 3656, bytes this sub-read = 3656, offset = 5688)\n"
          ]
        }
      ],
      "source": [
        "n_total_steps = len(train_loader)\n",
        "num_epochs = 20\n",
        "\n",
        "max_val = 0.\n",
        "PATH = os.path.join(dir,'models/cnn_v1.pth')\n",
        "\n",
        "train_loss,val_loss = np.zeros(num_epochs,dtype=np.float32),np.zeros(num_epochs,dtype=np.float32)\n",
        "train_acc,val_acc = np.zeros(num_epochs,dtype=np.float32),np.zeros(num_epochs,dtype=np.float32)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_correct,train_samples = 0,0\n",
        "    val_correct,val_samples = 0,0\n",
        "    for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
        "        # origin shape: [32, 3, 224, 224] = 32, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)#+nn.L1Loss(outputs,labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_samples += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_acc[epoch] = 100.0 * train_correct / train_samples\n",
        "    train_loss[epoch] = loss.item()\n",
        "    print('train loss $.3f - train acc. %.2f' %(train_loss[epoch],train_acc[epoch]))\n",
        "\n",
        "\n",
        "    for val_images, val_labels in val_loader:\n",
        "        val_images = val_images.to(device)\n",
        "        val_labels = val_labels.to(device)\n",
        "        outputs = model(val_images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        val_samples += val_labels.size(0)\n",
        "        val_correct += (predicted == val_labels).sum().item()\n",
        "    val_acc = 100.0 * val_correct / val_samples\n",
        "    if val_acc > max_val:\n",
        "        max_val = val_acc\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "    print('Val acc. %.2f' %(val_acc))\n",
        "\n",
        "\n",
        "        #if (i+1) % 200 == 0:\n",
        "            #print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "print('Finished Training')"
      ],
      "id": "CbBgZijYwH2E"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bird_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}