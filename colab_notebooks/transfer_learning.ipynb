{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "H5oajkLblM_T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5oajkLblM_T",
        "outputId": "6495400d-d3a8-4c11-edcd-62bdf5318787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BirdPics'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 66 (delta 22), reused 42 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (66/66), 6.79 MiB | 14.74 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n",
            "mv: cannot move 'BirdPics/utils' to './utils': Directory not empty\n",
            "total 8\n",
            "drwxr-xr-x 1 root root 4096 Nov  4 14:36 sample_data\n",
            "drwxr-xr-x 3 root root 4096 Nov  6 13:57 utils\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jgbeni/BirdPics.git\n",
        "!mv BirdPics/utils .\n",
        "!rm -r BirdPics\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "04580ba5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04580ba5",
        "outputId": "2c498953-62ce-4fc9-85ba-3bbaa1fd7e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import utils.data_preprocessing as dp\n",
        "import numpy as np\n",
        "import h5py\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "JPe0jNTcliwL",
      "metadata": {
        "id": "JPe0jNTcliwL"
      },
      "outputs": [],
      "source": [
        "dir = '/content/drive/MyDrive/BirdPics'\n",
        "os.makedirs(dir+'/models',exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "38a7101f",
      "metadata": {
        "id": "38a7101f"
      },
      "outputs": [],
      "source": [
        "f = h5py.File(dir+'/data/bird_data.hdf5', \"r\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "_5K1ZQbjoTqD",
      "metadata": {
        "id": "_5K1ZQbjoTqD"
      },
      "outputs": [],
      "source": [
        "X_train,Y_train = f['train']['X'],np.copy(f['train']['Y'])\n",
        "X_val,Y_val = f['val']['X'],np.copy(f['val']['Y'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dd03c10b",
      "metadata": {
        "id": "dd03c10b"
      },
      "outputs": [],
      "source": [
        "Y_train = dp.prepare_labels(Y_train)\n",
        "Y_val = dp.prepare_labels(Y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "VIfZN8Tpodmz",
      "metadata": {
        "id": "VIfZN8Tpodmz"
      },
      "outputs": [],
      "source": [
        "train_dataset = dp.HDF5Dataset(X_train,Y_train,train=True)\n",
        "val_dataset = dp.HDF5Dataset(X_val,Y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wBfvpfufo-lu",
      "metadata": {
        "id": "wBfvpfufo-lu"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, num_workers=8, batch_size=batch_size, pin_memory=True,\n",
        "                                                shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, num_workers=8, batch_size=batch_size, pin_memory=True,\n",
        "                                                shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BfoyRVnDHxPh",
      "metadata": {
        "id": "BfoyRVnDHxPh"
      },
      "source": [
        "## Choosing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "79157053",
      "metadata": {
        "id": "79157053",
        "outputId": "04bdbfb0-b8a5-4063-b4f7-d5857250a3fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 548M/548M [00:07<00:00, 79.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): ReLU(inplace=True)\n",
            "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): ReLU(inplace=True)\n",
            "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained ResNet50 model\n",
        "model = models.vgg19(weights='DEFAULT')\n",
        "model_path = 'models/vgg19_retrained.pth'\n",
        "loss_acc_path = 'models/vgg19_retrained.npz'\n",
        "# Print the model architecture\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier[-1] = nn.Linear(in_features=4096, out_features=3)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "uniU_siYdJg0"
      },
      "id": "uniU_siYdJg0",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "Ou53fmfZJz6C",
      "metadata": {
        "id": "Ou53fmfZJz6C"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pOkJhcL2vFHS",
      "metadata": {
        "id": "pOkJhcL2vFHS"
      },
      "outputs": [],
      "source": [
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.00005 ,weight_decay=1e-3)\n",
        "\n",
        "#LR decay\n",
        "decayRate = 0.96\n",
        "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CbBgZijYwH2E",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbBgZijYwH2E",
        "outputId": "4a4e4365-cc35-4992-dcf0-7443a3362efa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/312 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 312/312 [02:03<00:00,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 2.221 - train acc. 37.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 1.051 - val acc. 50.29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:03<00:00,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 1.051 - train acc. 42.75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 1.039 - val acc. 51.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:09<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 1.040 - train acc. 43.22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.993 - val acc. 55.15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 159/312 [01:06<00:47,  3.19it/s]"
          ]
        }
      ],
      "source": [
        "n_total_steps = len(train_loader)\n",
        "num_epochs = 20\n",
        "\n",
        "max_val = 0.\n",
        "PATH = os.path.join(dir,model_path)\n",
        "\n",
        "train_loss,val_loss = np.zeros(num_epochs,dtype=np.float32),np.zeros(num_epochs,dtype=np.float32)\n",
        "train_acc,val_acc = np.zeros(num_epochs,dtype=np.float32),np.zeros(num_epochs,dtype=np.float32)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_correct,train_samples = 0,0\n",
        "    val_correct,val_samples = 0,0\n",
        "    for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
        "        # origin shape: [32, 3, 224, 224] = 32, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_loss[epoch] += loss.item()/len(train_loader)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_samples += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_acc[epoch] = 100.0 * train_correct / train_samples\n",
        "    print('train loss %.4f - train acc. %.2f' %(train_loss[epoch],train_acc[epoch]))\n",
        "\n",
        "\n",
        "    for val_images, val_labels in val_loader:\n",
        "        val_images = val_images.to(device)\n",
        "        val_labels = val_labels.type(torch.LongTensor)\n",
        "        val_labels = val_labels.to(device)\n",
        "        outputs = model(val_images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        val_samples += val_labels.size(0)\n",
        "        val_correct += (predicted == val_labels).sum().item()\n",
        "\n",
        "        val_loss[epoch] += criterion(outputs, val_labels).item()/len(val_loader)\n",
        "    val_acc[epoch] = 100.0 * val_correct / val_samples\n",
        "    if val_acc[epoch] > max_val:\n",
        "        max_val = val_acc[epoch]\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "    print('val loss %.4f - val acc. %.2f' %(val_loss[epoch],val_acc[epoch]))\n",
        "\n",
        "    lr_scheduler.step()\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kLUEtPC9DN3d",
      "metadata": {
        "id": "kLUEtPC9DN3d"
      },
      "outputs": [],
      "source": [
        "np.savez(os.path.join(dir,loss_acc_path),train_loss=train_loss,val_loss=val_loss,train_acc=train_acc,val_acc=val_acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}