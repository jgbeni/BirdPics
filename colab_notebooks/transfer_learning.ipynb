{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "-fGnvQEq5X7c",
      "metadata": {
        "id": "-fGnvQEq5X7c"
      },
      "source": [
        "# Model training via transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PpU-hq3b5grW",
      "metadata": {
        "id": "PpU-hq3b5grW"
      },
      "source": [
        "In this notebook we will briefly see how the vision models have been trained with the BirdPics dataset. \n",
        "\n",
        "⚠️ It is **necessary** that you have already **downloaded** the dataset to your personal Drive. You can do it via the notebook '*colab_notebooks/download_gdrive.ipynb*'.\n",
        "\n",
        "In this project the Pytorch package has been used for the Machine Learning protocol. We are using *tranfer learning*, which means that we are loading large models that have already been trained for computer vision and retraining them with the BirdPics dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Sd5qMDFHLNxn",
      "metadata": {
        "id": "Sd5qMDFHLNxn"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3KzthOKORVAn",
      "metadata": {
        "id": "3KzthOKORVAn"
      },
      "source": [
        "We first load the GitHub repository to be able to use the built in functions found in the *utils* folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "H5oajkLblM_T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5oajkLblM_T",
        "outputId": "d0541e70-61b5-47d1-f396-3d929ec8a7c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'BirdPics' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jgbeni/BirdPics.git\n",
        "!mv BirdPics/utils .\n",
        "!rm -rf BirdPics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J1cKpAqJRvy2",
      "metadata": {
        "id": "J1cKpAqJRvy2"
      },
      "source": [
        "We import the required packages and mount the Drive. Ideally, the code should be run with a GPU for a significant speedup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04580ba5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04580ba5",
        "outputId": "cddfd841-b977-47dc-8525-5c4612518c73"
      },
      "outputs": [],
      "source": [
        "import utils.data_preprocessing as dp #This is the package found in the GitHub repository\n",
        "import numpy as np\n",
        "import h5py\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MNKKvkKAMIg5",
      "metadata": {
        "id": "MNKKvkKAMIg5"
      },
      "source": [
        "## Loading and preparing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CljHfzK6X6YG",
      "metadata": {
        "id": "CljHfzK6X6YG"
      },
      "source": [
        "We create a *models* folder to save the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "JPe0jNTcliwL",
      "metadata": {
        "id": "JPe0jNTcliwL"
      },
      "outputs": [],
      "source": [
        "dir = '/content/drive/MyDrive/BirdPics'\n",
        "os.makedirs(dir+'/models',exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e-f3fiA-YNIN",
      "metadata": {
        "id": "e-f3fiA-YNIN"
      },
      "source": [
        "We load training and validation images (*X*) and labels (*Y*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "38a7101f",
      "metadata": {
        "id": "38a7101f"
      },
      "outputs": [],
      "source": [
        "# Run this cell only once to avoid running our of RAM memory\n",
        "f = h5py.File(dir+'/data/bird_data.hdf5', \"r\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "_5K1ZQbjoTqD",
      "metadata": {
        "id": "_5K1ZQbjoTqD"
      },
      "outputs": [],
      "source": [
        "X_train,Y_train = f['train']['X'],f['train']['Y']\n",
        "X_val,Y_val = f['val']['X'],f['val']['Y']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "txo7GbqzaNoT",
      "metadata": {
        "id": "txo7GbqzaNoT"
      },
      "source": [
        "It is also important to encode the labels from strings to integers. In this notebook we have chosen the following encoding:\n",
        "\n",
        "\n",
        "*   swallow = 0\n",
        "*   swift = 1\n",
        "*   martin = 2\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dd03c10b",
      "metadata": {
        "id": "dd03c10b"
      },
      "outputs": [],
      "source": [
        "Y_train = dp.prepare_labels(Y_train)\n",
        "Y_val = dp.prepare_labels(Y_val)\n",
        "\n",
        "print('Sample of encoded training labels:',Y_train[0:8])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-kWavDbNfWpq",
      "metadata": {
        "id": "-kWavDbNfWpq"
      },
      "source": [
        "We load the dataset into a custom Pytorch Dataset class. It has been written to apply **data augmentation** (check notebook '*N2_image_preprocessing.ipynb*') for training data (*train = True*) and to leave the data intact otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "VIfZN8Tpodmz",
      "metadata": {
        "id": "VIfZN8Tpodmz"
      },
      "outputs": [],
      "source": [
        "train_dataset = dp.HDF5Dataset(X_train,Y_train,train=True)\n",
        "val_dataset = dp.HDF5Dataset(X_val,Y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IChOH8D1fh_f",
      "metadata": {
        "id": "IChOH8D1fh_f"
      },
      "source": [
        "And we create Pytorch dataloaders that will load the dataset into **minibatches** of size 64. This batch size can be changed depending on the machine capabilities: a larger batch size will fasten the training process at the expense of a higher memory cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "wBfvpfufo-lu",
      "metadata": {
        "id": "wBfvpfufo-lu"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, num_workers=2, batch_size=batch_size, pin_memory=True,\n",
        "                                                shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, num_workers=2, batch_size=batch_size, pin_memory=True,\n",
        "                                                shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BfoyRVnDHxPh",
      "metadata": {
        "id": "BfoyRVnDHxPh"
      },
      "source": [
        "## Choosing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f38fa32",
      "metadata": {},
      "source": [
        "In this example, we will use a pre-trained VGG16 model (https://www.kaggle.com/code/blurredmachine/vggnet-16-architecture-a-complete-guide) and fine-tune it for our bird species classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79157053",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79157053",
        "outputId": "94824bae-22b1-4d1a-b3ea-1ce06d18f132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained VGG16 model\n",
        "model = models.vgg16(weights='DEFAULT')\n",
        "# Other models can be loaded similarly, these are other examples that can be found in the repository:\n",
        "# model = models.vgg19(weights='DEFAULT') # VGG19 model\n",
        "# model = models.resnet50(weights='DEFAULT') # ResNet50 model\n",
        "\n",
        "model_path = 'models/vgg16_retrained.pth' # Path to save the retrained model\n",
        "loss_acc_path = 'models/vgg16_retrained.npz' # Path to save loss and accuracy data\n",
        "# Print the model architecture\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b758d05",
      "metadata": {},
      "source": [
        "It is important to rewrite the last linear layer to match the number of output features needed for our task (i.e., three output features):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uniU_siYdJg0",
      "metadata": {
        "id": "uniU_siYdJg0"
      },
      "outputs": [],
      "source": [
        "model.classifier[-1] = nn.Linear(in_features=4096, out_features=3) # Modify the last layer for 3 output features\n",
        "model = model.to(device) # Move the model to the appropriate device (ideally a GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "106232c9",
      "metadata": {},
      "source": [
        "Note that we are not *freezing* any of the model's layers, as is usual in most transfer-learning/fine-tuning protocols to avoir overfitting. In our case, as we are implementing **data augmentation** on the training dataset, we can safely optimize every model layer without finding any overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ou53fmfZJz6C",
      "metadata": {
        "id": "Ou53fmfZJz6C"
      },
      "source": [
        "## Training and saving the results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6c22819",
      "metadata": {},
      "source": [
        "Now we need to define the model hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pOkJhcL2vFHS",
      "metadata": {
        "id": "pOkJhcL2vFHS"
      },
      "outputs": [],
      "source": [
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.00005 ,weight_decay=1e-3)\n",
        "\n",
        "# Exponential learning rate decay\n",
        "decayRate = 0.96\n",
        "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42e4d430",
      "metadata": {},
      "source": [
        "Some insights and coments on the choices:\n",
        "- The learning rate (*lr*) has been set to a quite small value, $l_{r} = 5 \\cdot 10^{-5}$. This ensures the model parameters do not diverge too much from the default ones, which were already optimized for image classification. This way the model is just being fine-tuned for our concrete task.\n",
        "- The AdamW optimizer is chosen so the weight decay is decoupled from the learning rate, which improves generalization on image classification tasks (https://arxiv.org/abs/1711.05101).\n",
        "- An exponential learning rate decay is implemented to improve the optimization as the model gets closer to convergence."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a2b95e0",
      "metadata": {},
      "source": [
        "Now we end up with the training loop code, where we are saving the model every time the validation accuracy increases among epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CbBgZijYwH2E",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbBgZijYwH2E",
        "outputId": "f5b88688-a422-4840-958f-2b0cc8325a4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:26<00:00,  1.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 1.2603 - train acc. 46.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.9744 - val acc. 61.62\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:43<00:00,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.9377 - train acc. 52.58\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.8637 - val acc. 67.01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:43<00:00,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.8732 - train acc. 56.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.7700 - val acc. 74.46\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:43<00:00,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.8066 - train acc. 59.61\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.7350 - val acc. 76.67\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:43<00:00,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.7697 - train acc. 61.63\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.7193 - val acc. 78.38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:43<00:00,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.7309 - train acc. 63.77\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.6518 - val acc. 78.82\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:31<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.6987 - train acc. 65.06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.6676 - val acc. 79.95\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:31<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.6839 - train acc. 66.21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.5823 - val acc. 83.43\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:31<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.6642 - train acc. 66.64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.5422 - val acc. 84.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:31<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.6501 - train acc. 67.21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.5248 - val acc. 85.83\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:32<00:00,  1.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.6340 - train acc. 68.06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.5176 - val acc. 84.36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:32<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.6163 - train acc. 68.95\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.4924 - val acc. 87.16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:32<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.6113 - train acc. 69.06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.4986 - val acc. 84.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:31<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.6091 - train acc. 69.38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.4803 - val acc. 87.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:32<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.5963 - train acc. 69.73\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.4663 - val acc. 86.57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:32<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.5876 - train acc. 70.07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.4302 - val acc. 87.45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:32<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.5831 - train acc. 70.31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.4324 - val acc. 86.08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:31<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.5766 - train acc. 70.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.4005 - val acc. 87.60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:32<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.5637 - train acc. 71.33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.4129 - val acc. 87.50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [04:31<00:00,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.5690 - train acc. 70.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss 0.4374 - val acc. 88.77\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 20 # number of epochs for training\n",
        "\n",
        "max_val = 0.0 # variable to store the maximum validation accuracy achieved during training (starting at 0) \n",
        "PATH = os.path.join(dir,model_path) # full path to save the model\n",
        "\n",
        "# Arrays to store loss and accuracy values\n",
        "train_loss,val_loss = np.zeros(num_epochs,dtype=np.float32),np.zeros(num_epochs,dtype=np.float32)\n",
        "train_acc,val_acc = np.zeros(num_epochs,dtype=np.float32),np.zeros(num_epochs,dtype=np.float32)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch %d/%d' %(epoch+1,num_epochs))\n",
        "    train_correct,train_samples = 0,0 # variables to count correct predictions and total samples in training\n",
        "    val_correct,val_samples = 0,0 # variables to count correct predictions and total samples in validation\n",
        "    for i, (images, labels) in enumerate(tqdm(train_loader)): # loop over training batches\n",
        "        images = images.to(device) # move images to GPU\n",
        "        labels = labels.type(torch.LongTensor) # ensure labels are of type LongTensor\n",
        "        labels = labels.to(device) # move labels to GPU\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_loss[epoch] += loss.item()/len(train_loader) # accumulate training loss\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1) # get the index of the max log-probability\n",
        "        train_samples += labels.size(0) # update total number of training samples\n",
        "        train_correct += (predicted == labels).sum().item() # update number of correct predictions\n",
        "\n",
        "    train_acc[epoch] = 100.0 * train_correct / train_samples # calculate training accuracy\n",
        "    print('train loss %.4f - train acc. %.2f' %(train_loss[epoch],train_acc[epoch]))\n",
        "\n",
        "\n",
        "    for val_images, val_labels in val_loader: # loop over validation batches\n",
        "        val_images = val_images.to(device) # move images to GPU\n",
        "        val_labels = val_labels.type(torch.LongTensor) # ensure labels are of type LongTensor\n",
        "        val_labels = val_labels.to(device) # move labels to GPU\n",
        "\n",
        "        outputs = model(val_images)\n",
        "        _, predicted = torch.max(outputs, 1) # get the index of the max log-probability\n",
        "        val_samples += val_labels.size(0) # update total number of validation samples\n",
        "        val_correct += (predicted == val_labels).sum().item() # update number of correct predictions\n",
        "\n",
        "        val_loss[epoch] += criterion(outputs, val_labels).item()/len(val_loader) # accumulate validation loss\n",
        "    val_acc[epoch] = 100.0 * val_correct / val_samples # calculate validation accuracy\n",
        "    if val_acc[epoch] > max_val: # save model if current validation accuracy is greater than the previous maximum\n",
        "        max_val = val_acc[epoch]\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "    print('val loss %.4f - val acc. %.2f' %(val_loss[epoch],val_acc[epoch]))\n",
        "\n",
        "    lr_scheduler.step() # update learning rate\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48a9bf5c",
      "metadata": {},
      "source": [
        "And we finally save the loss and accuracy trajectories in an .npz file for further evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "kLUEtPC9DN3d",
      "metadata": {
        "id": "kLUEtPC9DN3d"
      },
      "outputs": [],
      "source": [
        "np.savez(os.path.join(dir,loss_acc_path),train_loss=train_loss,val_loss=val_loss,train_acc=train_acc,val_acc=val_acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
